# =========================================================
# Monitoring Stack Deployment Workflow
# =========================================================
# This workflow manages Prometheus and Grafana monitoring
# deployment on EKS clusters across different environments.
#
# Features:
# - Manual trigger with environment selection
# - Install/Uninstall monitoring stack
# - Environment-specific configurations
# - Comprehensive logging and status reporting
# =========================================================

name: monitoring-deployment

on:
  workflow_dispatch:
    inputs:
      environment:
        description: 'Target Environment'
        required: true
        default: 'dev'
        type: choice
        options:
          - dev
          - staging
          - prod
      action:
        description: 'Monitoring Action'
        required: true
        default: 'install'
        type: choice
        options:
          - install
          - uninstall
          - status
      helm_timeout:
        description: 'Helm Operation Timeout (minutes)'
        required: false
        default: '10'
        type: string

# ---------------------------------------------------------
# Environment Variables
# ---------------------------------------------------------
env:
  AWS_REGION: us-east-1
  EKS_CLUSTER_NAME: kudos-app-${{ github.event.inputs.environment || 'dev' }}
  MONITORING_NAMESPACE: monitoring
  HELM_RELEASE_NAME: kube-prometheus-stack
  HELM_TIMEOUT: ${{ github.event.inputs.helm_timeout || '10' }}m

# ---------------------------------------------------------
# Jobs
# ---------------------------------------------------------
jobs:
  # ---------------------------------------------------------
  # 1. Monitoring Stack Management
  # ---------------------------------------------------------
  manage-monitoring:
    name: "ğŸ“Š ${{ github.event.inputs.action }} Monitoring Stack"
    runs-on: ubuntu-latest
    environment: ${{ github.event.inputs.environment || 'dev' }}
    
    steps:
      - name: "ğŸ” Checkout Repository"
        uses: actions/checkout@v4

      - name: "ğŸ”‘ Configure AWS Credentials"
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}

      - name: "âš™ï¸ Setup kubectl"
        uses: azure/setup-kubectl@v4
        with:
          version: v1.29.0

      - name: "ğŸ¡ Setup Helm"
        uses: azure/setup-helm@v4
        with:
          version: v3.19.0

      - name: "ğŸ”— Update kubeconfig for EKS"
        run: |
          echo "ğŸ” Environment: ${{ github.event.inputs.environment || 'dev' }}"
          echo "ğŸ¯ Target EKS cluster: $EKS_CLUSTER_NAME"
          echo "ğŸŒ AWS Region: $AWS_REGION"
          echo "ğŸ“Š Action: ${{ github.event.inputs.action }}"
          
          # Test AWS CLI authentication
          echo "ğŸ” Testing AWS CLI authentication..."
          aws sts get-caller-identity
          
          # Check if cluster exists
          echo "ğŸ” Checking if EKS cluster exists..."
          if aws eks describe-cluster --name $EKS_CLUSTER_NAME --region $AWS_REGION; then
            echo "âœ… EKS cluster found: $EKS_CLUSTER_NAME"
          else
            echo "âŒ EKS cluster not found or not accessible"
            echo "Available clusters:"
            aws eks list-clusters --region $AWS_REGION || echo "Failed to list clusters"
            exit 1
          fi
          
          # Update kubeconfig
          echo "ğŸ”„ Updating kubeconfig..."
          aws eks update-kubeconfig --region $AWS_REGION --name $EKS_CLUSTER_NAME
          
          # Test cluster connectivity
          echo "ğŸ”— Testing cluster connectivity..."
          if kubectl cluster-info; then
            echo "âœ… Successfully connected to cluster"
          else
            echo "âŒ Failed to connect to cluster"
            exit 1
          fi
          
          # Show current context
          echo "ğŸ“‹ Current kubectl context:"
          kubectl config current-context

      - name: "âœ… Verify Cluster Access"
        run: |
          echo "ğŸ” Verifying cluster access and permissions..."
          
          # Check nodes
          echo "ğŸ–¥ï¸ Cluster nodes:"
          kubectl get nodes -o wide
          
          # Check current namespace and permissions
          echo "ğŸ“ Current namespace:"
          kubectl config view --minify --output 'jsonpath={..namespace}' || echo 'default'
          
          # Test basic permissions
          echo "ğŸ” Testing basic permissions:"
          kubectl auth can-i create namespaces
          kubectl auth can-i create deployments
          kubectl auth can-i create services
          kubectl auth can-i create configmaps
          kubectl auth can-i create secrets
          
          echo "âœ… Cluster access verification completed"

      # ---------------------------------------------------------
      # Setup Prerequisites (EBS CSI Driver, OIDC, IRSA)
      # ---------------------------------------------------------
      - name: "ğŸ”§ Setup EBS CSI Driver with IRSA"
        if: github.event.inputs.action == 'install'
        run: |
          echo "ğŸ”§ Setting up EBS CSI Driver prerequisites..."
          
          # Get cluster info
          CLUSTER_NAME="$EKS_CLUSTER_NAME"
          
          # Get OIDC issuer URL
          OIDC_ISSUER=$(aws eks describe-cluster --region $AWS_REGION --name $CLUSTER_NAME --query "cluster.identity.oidc.issuer" --output text)
          OIDC_ID=$(echo $OIDC_ISSUER | cut -d'/' -f5)
          
          echo "âœ… Cluster: $CLUSTER_NAME"
          echo "âœ… OIDC Issuer: $OIDC_ISSUER"
          echo "âœ… OIDC ID: $OIDC_ID"
          
          # Check if OIDC provider exists
          echo "ğŸ” Checking OIDC provider..."
          OIDC_EXISTS=$(aws iam list-open-id-connect-providers --query "OpenIDConnectProviderList[?ends_with(Arn, '$OIDC_ID')].Arn" --output text)
          
          if [ -z "$OIDC_EXISTS" ]; then
            echo "ğŸ“ Creating OIDC provider..."
            aws iam create-open-id-connect-provider \
              --url $OIDC_ISSUER \
              --client-id-list sts.amazonaws.com \
              --thumbprint-list 9e99a48a9960b14926bb7f3b02e22da2b0ab7280
            echo "âœ… OIDC provider created"
          else
            echo "âœ… OIDC provider already exists: $OIDC_EXISTS"
          fi
          
          # Check if IAM role exists
          echo "ğŸ” Checking EBS CSI IAM role..."
          ROLE_EXISTS=$(aws iam get-role --role-name AmazonEKS_EBS_CSI_DriverRole --query 'Role.RoleName' --output text 2>/dev/null || echo "")
          
          if [ "$ROLE_EXISTS" != "AmazonEKS_EBS_CSI_DriverRole" ]; then
            echo "ğŸ“ Creating EBS CSI IAM role..."
            
            # Create trust policy
            cat > ebs-csi-trust-policy.json << EOF
          {
            "Version": "2012-10-17", 
            "Statement": [
              {
                "Effect": "Allow",
                "Principal": {
                  "Federated": "arn:aws:iam::${{ vars.AWS_ACCOUNT_ID || secrets.AWS_ACCOUNT_ID }}:oidc-provider/${OIDC_ISSUER#https://}"
                },
                "Action": "sts:AssumeRoleWithWebIdentity",
                "Condition": {
                  "StringEquals": {
                    "${OIDC_ISSUER#https://}:sub": "system:serviceaccount:kube-system:ebs-csi-controller-sa",
                    "${OIDC_ISSUER#https://}:aud": "sts.amazonaws.com"
                  }
                }
              }
            ]
          }
          EOF
            
            # Create role and attach policy
            aws iam create-role --role-name AmazonEKS_EBS_CSI_DriverRole --assume-role-policy-document file://ebs-csi-trust-policy.json
            aws iam attach-role-policy --role-name AmazonEKS_EBS_CSI_DriverRole --policy-arn arn:aws:iam::aws:policy/service-role/AmazonEBSCSIDriverPolicy
            echo "âœ… EBS CSI IAM role created and policy attached"
          else
            echo "âœ… EBS CSI IAM role already exists"
          fi
          
          # Check if EBS CSI addon exists
          echo "ğŸ” Checking EBS CSI addon..."
          ADDON_STATUS=$(aws eks describe-addon --cluster-name $CLUSTER_NAME --addon-name aws-ebs-csi-driver --region $AWS_REGION --query 'addon.status' --output text 2>/dev/null || echo "NOT_FOUND")
          
          if [ "$ADDON_STATUS" != "ACTIVE" ]; then
            echo "ğŸ“ Installing EBS CSI driver addon..."
            
            # Delete addon if it exists in failed state
            if [ "$ADDON_STATUS" != "NOT_FOUND" ]; then
              echo "ğŸ—‘ï¸ Removing existing addon in $ADDON_STATUS state..."
              aws eks delete-addon --cluster-name $CLUSTER_NAME --addon-name aws-ebs-csi-driver --region $AWS_REGION
              aws eks wait addon-deleted --cluster-name $CLUSTER_NAME --addon-name aws-ebs-csi-driver --region $AWS_REGION
            fi
            
            # Install addon with IAM role
            aws eks create-addon \
              --cluster-name $CLUSTER_NAME \
              --addon-name aws-ebs-csi-driver \
              --service-account-role-arn arn:aws:iam::${{ vars.AWS_ACCOUNT_ID || secrets.AWS_ACCOUNT_ID }}:role/AmazonEKS_EBS_CSI_DriverRole \
              --region $AWS_REGION
            
            echo "â³ Waiting for EBS CSI driver to be active..."
            timeout 300 aws eks wait addon-active --cluster-name $CLUSTER_NAME --addon-name aws-ebs-csi-driver --region $AWS_REGION
            echo "âœ… EBS CSI driver installed and active"
          else
            echo "âœ… EBS CSI driver already active"
          fi
          
          # Verify EBS CSI driver pods are running
          echo "ğŸ” Verifying EBS CSI driver pods..."
          kubectl get pods -n kube-system -l app=ebs-csi-controller
          echo "âœ… EBS CSI driver setup completed"

      # ---------------------------------------------------------
      # Install Monitoring Stack
      # ---------------------------------------------------------
      - name: "ğŸ“¦ Install Monitoring Stack"
        if: github.event.inputs.action == 'install'
        run: |
          echo "ğŸ“Š Installing Prometheus and Grafana monitoring stack..."
          echo "ğŸ¯ Environment: ${{ github.event.inputs.environment }}"
          echo "â±ï¸ Timeout: $HELM_TIMEOUT"
          
          # Make scripts executable
          chmod +x monitoring/install-monitoring.sh
          
          # Set environment variables for the script
          export ENVIRONMENT="${{ github.event.inputs.environment }}"
          export CLUSTER_NAME="$EKS_CLUSTER_NAME"
          
          # Run installation script
          cd monitoring
          ./install-monitoring.sh
          
          echo "âœ… Monitoring stack installation completed!"

      # ---------------------------------------------------------
      # Uninstall Monitoring Stack  
      # ---------------------------------------------------------
      - name: "ğŸ—‘ï¸ Uninstall Monitoring Stack"
        if: github.event.inputs.action == 'uninstall'
        run: |
          echo "ğŸ—‘ï¸ Removing Prometheus and Grafana monitoring stack..."
          echo "ğŸ¯ Environment: ${{ github.event.inputs.environment }}"
          
          # Make scripts executable
          chmod +x monitoring/uninstall-monitoring.sh
          
          # Set environment variables for the script
          export ENVIRONMENT="${{ github.event.inputs.environment }}"
          export CLUSTER_NAME="$EKS_CLUSTER_NAME"
          
          # Run uninstallation script with auto-confirm
          cd monitoring
          echo "y" | ./uninstall-monitoring.sh
          
          echo "âœ… Monitoring stack removal completed!"

      # ---------------------------------------------------------
      # Check Monitoring Status
      # ---------------------------------------------------------
      - name: "ğŸ“‹ Check Monitoring Status"
        if: always()
        run: |
          echo "ğŸ“Š === MONITORING STACK STATUS ==="
          echo "ğŸ”– Environment: ${{ github.event.inputs.environment || 'dev' }}"
          echo "ğŸ¯ EKS Cluster: $EKS_CLUSTER_NAME"
          echo "ğŸŒ AWS Region: $AWS_REGION"
          echo "âš¡ Action Performed: ${{ github.event.inputs.action }}"
          echo
          
          # Check if monitoring namespace exists
          if kubectl get namespace $MONITORING_NAMESPACE &> /dev/null; then
            echo "âœ… Monitoring namespace exists"
            echo
            
            # Check Helm releases in monitoring namespace
            echo "ğŸ¡ Helm Releases in monitoring namespace:"
            helm list -n $MONITORING_NAMESPACE || echo "No Helm releases found"
            echo
            
            # Check pods in monitoring namespace
            echo "ğŸ³ Pods in monitoring namespace:"
            kubectl get pods -n $MONITORING_NAMESPACE -o wide || echo "No pods found"
            echo
            
            # Check services in monitoring namespace
            echo "ğŸŒ Services in monitoring namespace:"
            kubectl get services -n $MONITORING_NAMESPACE || echo "No services found"
            echo
            
            # Check persistent volumes
            echo "ğŸ’¾ Persistent Volume Claims:"
            kubectl get pvc -n $MONITORING_NAMESPACE || echo "No PVCs found"
            echo
            
            # If Grafana is running, show access information
            if kubectl get pods -n $MONITORING_NAMESPACE -l "app.kubernetes.io/name=grafana" | grep -q "Running"; then
              echo "ğŸ“Š Grafana Access Information:"
              echo "   1. Port forward: kubectl port-forward -n $MONITORING_NAMESPACE svc/kube-prometheus-stack-grafana 3000:80"
              echo "   2. URL: http://localhost:3000"
              echo "   3. Username: admin"
              echo "   4. Get password: kubectl get secret -n $MONITORING_NAMESPACE kube-prometheus-stack-grafana -o jsonpath=\"{.data.admin-password}\" | base64 --decode && echo"
              echo
            fi
            
            # If Prometheus is running, show access information
            if kubectl get pods -n $MONITORING_NAMESPACE -l "app.kubernetes.io/name=prometheus" | grep -q "Running"; then
              echo "ğŸ” Prometheus Access Information:"
              echo "   1. Port forward: kubectl port-forward -n $MONITORING_NAMESPACE svc/kube-prometheus-stack-prometheus 9090:9090"
              echo "   2. URL: http://localhost:9090"
              echo "   3. Check targets: http://localhost:9090/targets"
              echo
            fi
          else
            echo "âŒ Monitoring namespace not found"
            echo "ğŸ’¡ Run this workflow with action 'install' to deploy monitoring stack"
          fi

      # ---------------------------------------------------------
      # Generate Monitoring Report
      # ---------------------------------------------------------
      - name: "ğŸ“Š Generate Monitoring Report"
        if: always()
        run: |
          echo "# ğŸ“Š Monitoring Stack Deployment Report" > monitoring-report.md
          echo "" >> monitoring-report.md
          echo "**Date:** $(date -u)" >> monitoring-report.md
          echo "**Environment:** ${{ github.event.inputs.environment || 'dev' }}" >> monitoring-report.md
          echo "**Action:** ${{ github.event.inputs.action }}" >> monitoring-report.md
          echo "**EKS Cluster:** $EKS_CLUSTER_NAME" >> monitoring-report.md
          echo "**AWS Region:** $AWS_REGION" >> monitoring-report.md
          echo "**Workflow Run:** ${{ github.run_id }}" >> monitoring-report.md
          echo "" >> monitoring-report.md
          
          # Add status information
          if kubectl get namespace $MONITORING_NAMESPACE &> /dev/null; then
            echo "## âœ… Monitoring Stack Status: ACTIVE" >> monitoring-report.md
            echo "" >> monitoring-report.md
            echo "### Components:" >> monitoring-report.md
            echo '```' >> monitoring-report.md
            kubectl get pods -n $MONITORING_NAMESPACE >> monitoring-report.md 2>/dev/null || echo "No pods found" >> monitoring-report.md
            echo '```' >> monitoring-report.md
            echo "" >> monitoring-report.md
            echo "### Services:" >> monitoring-report.md
            echo '```' >> monitoring-report.md
            kubectl get svc -n $MONITORING_NAMESPACE >> monitoring-report.md 2>/dev/null || echo "No services found" >> monitoring-report.md
            echo '```' >> monitoring-report.md
          else
            echo "## âŒ Monitoring Stack Status: NOT INSTALLED" >> monitoring-report.md
          fi
          
          echo "" >> monitoring-report.md
          echo "### Quick Access Commands:" >> monitoring-report.md
          echo "" >> monitoring-report.md
          echo "**Grafana:**" >> monitoring-report.md
          echo '```bash' >> monitoring-report.md
          echo "kubectl port-forward -n $MONITORING_NAMESPACE svc/kube-prometheus-stack-grafana 3000:80" >> monitoring-report.md
          echo '```' >> monitoring-report.md
          echo "" >> monitoring-report.md
          echo "**Prometheus:**" >> monitoring-report.md
          echo '```bash' >> monitoring-report.md
          echo "kubectl port-forward -n $MONITORING_NAMESPACE svc/kube-prometheus-stack-prometheus 9090:9090" >> monitoring-report.md
          echo '```' >> monitoring-report.md
          echo "" >> monitoring-report.md
          echo "**Get Grafana Password:**" >> monitoring-report.md
          echo '```bash' >> monitoring-report.md
          echo "kubectl get secret -n $MONITORING_NAMESPACE kube-prometheus-stack-grafana -o jsonpath=\"{.data.admin-password}\" | base64 --decode && echo" >> monitoring-report.md
          echo '```' >> monitoring-report.md
          
          echo "ğŸ“ Monitoring report generated: monitoring-report.md"

      # ---------------------------------------------------------
      # Upload Report Artifact
      # ---------------------------------------------------------
      - name: "ğŸ“¤ Upload Monitoring Report"
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: monitoring-report-${{ github.event.inputs.environment }}-${{ github.run_id }}
          path: monitoring-report.md
          retention-days: 30

      # ---------------------------------------------------------
      # Final Status Notification
      # ---------------------------------------------------------
      - name: "ğŸ‰ Installation Success Notification"
        if: success() && github.event.inputs.action == 'install'
        run: |
          echo "âœ… Monitoring Stack Successfully Installed!"
          echo "ğŸ¯ Environment: ${{ github.event.inputs.environment }}"
          echo "ğŸ·ï¸ EKS Cluster: $EKS_CLUSTER_NAME"
          echo ""
          echo "ğŸ“Š Next Steps:"
          echo "1. Access Grafana: kubectl port-forward -n $MONITORING_NAMESPACE svc/kube-prometheus-stack-grafana 3000:80"
          echo "2. Open http://localhost:3000"
          echo "3. Login with admin/[get password from secret]"
          echo "4. Explore pre-built Kubernetes dashboards"
          echo ""
          echo "ğŸ” Prometheus: kubectl port-forward -n $MONITORING_NAMESPACE svc/kube-prometheus-stack-prometheus 9090:9090"

      - name: "âœ… Uninstallation Success Notification"
        if: success() && github.event.inputs.action == 'uninstall'
        run: |
          echo "âœ… Monitoring Stack Successfully Removed!"
          echo "ğŸ¯ Environment: ${{ github.event.inputs.environment }}"
          echo "ğŸ·ï¸ EKS Cluster: $EKS_CLUSTER_NAME"
          echo ""
          echo "ğŸ—‘ï¸ Removed Components:"
          echo "- Prometheus Server"
          echo "- Grafana Dashboards"
          echo "- AlertManager"
          echo "- Node Exporter"
          echo "- kube-state-metrics"
          echo "- Prometheus Operator"
          echo ""
          echo "ğŸ’¡ To reinstall: Run this workflow again with action 'install'"

      - name: "ğŸš¨ Failure Notification"
        if: failure()
        run: |
          echo "âŒ Monitoring Stack Operation Failed!"
          echo "ğŸ¯ Environment: ${{ github.event.inputs.environment }}"
          echo "âš¡ Action: ${{ github.event.inputs.action }}"
          echo "ğŸ·ï¸ EKS Cluster: $EKS_CLUSTER_NAME"
          echo ""
          echo "ğŸ” Troubleshooting Steps:"
          echo "1. Check the logs above for specific error messages"
          echo "2. Verify EKS cluster is accessible"
          echo "3. Check AWS credentials and permissions"
          echo "4. Verify Helm is properly installed"
          echo "5. Check if resources already exist (for install) or don't exist (for uninstall)"
          echo ""
          echo "ğŸ“‹ Get current status:"
          echo "kubectl get all -n $MONITORING_NAMESPACE"
          echo "helm list -n $MONITORING_NAMESPACE"