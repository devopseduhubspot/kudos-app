name: ğŸ—ï¸ Infrastructure Management

on:
  # Manual trigger with input options
  workflow_dispatch:
    inputs:
      action:
        description: 'Terraform Action'
        required: true
        default: 'plan'
        type: choice
        options:
          - plan
          - apply
          - destroy
      environment:
        description: 'Environment'
        required: true
        default: 'dev'
        type: choice
        options:
          - dev
          - staging
          - prod
      auto_approve:
        description: 'Auto-approve (apply/destroy only)'
        required: false
        default: false
        type: boolean

env:
  TF_VAR_app_name: kudos-app-${{ github.event.inputs.environment }}
  AWS_REGION: us-east-1

jobs:
  terraform:
    name: ğŸš€ Terraform ${{ github.event.inputs.action }}
    runs-on: ubuntu-latest
    
    # Use environment for additional protection
    environment: ${{ github.event.inputs.environment }}
    
    defaults:
      run:
        working-directory: terraform
    
    steps:
      - name: ğŸ“¥ Checkout Code
        uses: actions/checkout@v4

      - name: ğŸ”§ Setup Terraform
        uses: hashicorp/setup-terraform@v3
        with:
          terraform_version: ~1.7.0

      - name: ğŸ” Configure AWS Credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}

      - name: ğŸ” Terraform Format Check
        id: fmt
        run: terraform fmt -check -recursive
        continue-on-error: true

      - name: ğŸ¯ Terraform Init
        id: init
        run: |
          terraform init \
            -backend-config="bucket=${{ secrets.TERRAFORM_STATE_BUCKET }}" \
            -backend-config="key=kudos-app/${{ github.event.inputs.environment }}/terraform.tfstate" \
            -backend-config="region=${{ env.AWS_REGION }}"

      - name: ğŸ” Terraform Validate
        id: validate
        run: terraform validate

      - name: ğŸ“Š Terraform Plan
        id: plan
        run: |
          terraform plan -no-color -out=tfplan
        continue-on-error: true

      - name: ğŸ“ Update PR with Plan
        if: github.event_name == 'pull_request' && steps.plan.outcome == 'success'
        uses: actions/github-script@v7
        env:
          PLAN: ${{ steps.plan.outputs.stdout }}
        with:
          script: |
            const output = `#### Terraform Format and Style ğŸ–Œ\`${{ steps.fmt.outcome }}\`
            #### Terraform Initialization âš™ï¸\`${{ steps.init.outcome }}\`
            #### Terraform Validation ğŸ¤–\`${{ steps.validate.outcome }}\`
            #### Terraform Plan ğŸ“–\`${{ steps.plan.outcome }}\`
            
            <details><summary>Show Plan</summary>
            
            \`\`\`terraform
            ${process.env.PLAN}
            \`\`\`
            
            </details>
            
            *Pusher: @${{ github.actor }}, Action: \`${{ github.event_name }}\`*`;
            
            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: output
            })

      - name: ğŸ” Check and Import Existing ECR Repositories
        if: github.event.inputs.action == 'apply' && steps.plan.outcome == 'success'
        run: |
          echo "ğŸ” Checking for existing ECR repositories..."
          
          # Define repository names based on environment
          FRONTEND_REPO="${{ env.TF_VAR_app_name }}"
          BACKEND_REPO="${{ env.TF_VAR_app_name }}-backend"
          
          echo "Frontend repo: $FRONTEND_REPO"
          echo "Backend repo: $BACKEND_REPO"
          
          # Check and import frontend repository if it exists
          if aws ecr describe-repositories --repository-names $FRONTEND_REPO --region ${{ env.AWS_REGION }} 2>/dev/null; then
            echo "ğŸ“¦ Found existing frontend repository: $FRONTEND_REPO"
            echo "ğŸ”„ Importing into Terraform state..."
            terraform import aws_ecr_repository.app $FRONTEND_REPO || echo "âš ï¸ Import failed or already imported"
          else
            echo "âœ… Frontend repository $FRONTEND_REPO does not exist - will be created"
          fi
          
          # Check and import backend repository if it exists  
          if aws ecr describe-repositories --repository-names $BACKEND_REPO --region ${{ env.AWS_REGION }} 2>/dev/null; then
            echo "ğŸ“¦ Found existing backend repository: $BACKEND_REPO"
            echo "ğŸ”„ Importing into Terraform state..."
            terraform import aws_ecr_repository.backend $BACKEND_REPO || echo "âš ï¸ Import failed or already imported"
          else
            echo "âœ… Backend repository $BACKEND_REPO does not exist - will be created"
          fi
          
          echo "ğŸ”„ Re-running plan after imports..."
          terraform plan -no-color -out=tfplan

      - name: âœ… Terraform Apply
        if: github.event.inputs.action == 'apply' && steps.plan.outcome == 'success'
        run: |
          if [ "${{ github.event.inputs.auto_approve }}" == "true" ]; then
            terraform apply -auto-approve tfplan
          else
            echo "âš ï¸ Manual approval required. Plan saved but not applied."
            echo "To apply manually, download the artifact and run: terraform apply tfplan"
          fi

      - name: ğŸ§¹ Cleanup Kubernetes Resources (Before Destroy)
        if: github.event.inputs.action == 'destroy'
        run: |
          echo "ğŸ§¹ Cleaning up Kubernetes resources before destroying infrastructure..."
          
          # Setup kubectl
          curl -LO "https://dl.k8s.io/release/v1.29.0/bin/linux/amd64/kubectl"
          sudo install -o root -g root -m 0755 kubectl /usr/local/bin/kubectl
          
          # Configure kubectl for EKS cluster
          aws eks update-kubeconfig --region ${{ env.AWS_REGION }} --name ${{ env.TF_VAR_app_name }} || {
            echo "âš ï¸ EKS cluster not found, continuing with infrastructure destroy..."
            exit 0
          }
          
          echo "âœ… Connected to EKS cluster, cleaning up resources..."
          
          # Delete LoadBalancer services first (they create ELBs that block VPC deletion)
          echo "ğŸ—‘ï¸ Deleting LoadBalancer services..."
          kubectl get svc -o name | xargs -r kubectl delete --timeout=300s || true
          
          # Delete all application resources if k8s directory exists
          if [ -d "../k8s" ]; then
            echo "ğŸ—‘ï¸ Deleting all Kubernetes resources..."
            kubectl delete -k ../k8s/ --timeout=300s || true
          fi
          
          # Wait for AWS resources to be cleaned up
          echo "â³ Waiting for AWS LoadBalancers to be deleted..."
          sleep 60
          
          # Force cleanup any remaining ELBs
          echo "ğŸ” Checking for remaining ELBs..."
          aws elb describe-load-balancers --region ${{ env.AWS_REGION }} --query 'LoadBalancerDescriptions[].LoadBalancerName' --output text | tr '\t' '\n' | while read elb; do
            if [ -n "$elb" ]; then
              echo "ğŸ—‘ï¸ Force deleting ELB: $elb"
              aws elb delete-load-balancer --load-balancer-name "$elb" --region ${{ env.AWS_REGION }} || true
            fi
          done
          
          echo "âœ… Kubernetes cleanup completed"
        continue-on-error: true

      - name: ğŸ’¥ Terraform Destroy
        if: github.event.inputs.action == 'destroy'
        run: |
          if [ "${{ github.event.inputs.auto_approve }}" == "true" ]; then
            terraform destroy -auto-approve
          else
            echo "âš ï¸ Manual approval required for destroy operation."
            echo "To destroy manually, run: terraform destroy"
          fi

      - name: ğŸ“¦ Save Terraform Plan
        if: github.event.inputs.action == 'plan' || (github.event.inputs.action == 'apply' && github.event.inputs.auto_approve != 'true')
        uses: actions/upload-artifact@v4
        with:
          name: terraform-plan-${{ github.event.inputs.environment }}
          path: terraform/tfplan
          retention-days: 5

      - name: ğŸ“Š Terraform Output
        if: github.event.inputs.action == 'apply' && steps.plan.outcome == 'success'
        run: terraform output -json

      - name: ğŸ“ Summary Report
        run: |
          echo "## ğŸ—ï¸ Infrastructure Management Summary" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "- **Action**: ${{ github.event.inputs.action }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Environment**: ${{ github.event.inputs.environment }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Auto Approve**: ${{ github.event.inputs.auto_approve }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Triggered By**: @${{ github.actor }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Status**: ${{ job.status }}" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          if [ "${{ steps.plan.outcome }}" == "success" ]; then
            echo "âœ… Terraform plan executed successfully" >> $GITHUB_STEP_SUMMARY
          else
            echo "âŒ Terraform plan failed" >> $GITHUB_STEP_SUMMARY
          fi

  # Optional: Notify on completion
  notify:
    name: ğŸ“¢ Notification
    needs: terraform
    runs-on: ubuntu-latest
    if: always()
    steps:
      - name: ğŸ“§ Send Notification
        run: |
          echo "Infrastructure operation completed!"
          echo "Action: ${{ github.event.inputs.action }}"
          echo "Environment: ${{ github.event.inputs.environment }}"
          echo "Status: ${{ needs.terraform.result }}"