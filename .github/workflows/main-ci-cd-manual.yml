# =========================================================
# CI/CD Pipeline with AWS EKS Deployment
# =========================================================

name: main-ci-cd-manual

on:
  workflow_dispatch:
    inputs:
      environment:
        description: 'Deployment Environment'
        required: true
        default: 'dev'
        type: choice
        options:
          - dev
          - staging
          - prod
      mode:
        description: 'Pipeline Mode'
        required: true
        default: 'full-pipeline'
        type: choice
        options:
          - full-pipeline
          - docker-only
          - build-only

# ---------------------------------------------------------
# Environment Variables
# ---------------------------------------------------------
env:
  AWS_REGION: us-east-1
  EKS_CLUSTER_NAME: kudos-app-${{ github.event.inputs.environment || 'dev' }}
  ECR_REPOSITORY_FRONTEND: kudos-app-${{ github.event.inputs.environment || 'dev' }}-frontend
  ECR_REPOSITORY_BACKEND: kudos-app-${{ github.event.inputs.environment || 'dev' }}-backend
  IMAGE_TAG: ${{ github.sha }}
  BRANCH_NAME: ${{ github.ref_name }}
  BUILD_DATETIME: ${{ github.run_id }}-$(date +'%Y%m%d-%H%M%S')

# ---------------------------------------------------------
# 1. Install Dependencies
# ---------------------------------------------------------
jobs:
  install:
    name: "ğŸ“¦ Install Dependencies"
    runs-on: ubuntu-latest
    if: github.event.inputs.mode != 'docker-only'
    steps:
      - uses: actions/checkout@v4

      - uses: actions/setup-node@v4
        with:
          node-version: "18"
          cache: npm

      - run: npm ci

# ---------------------------------------------------------
# 2. Lint
# ---------------------------------------------------------
  lint:
    name: "ğŸ” Lint"
    runs-on: ubuntu-latest
    needs: install
    if: github.event.inputs.mode != 'docker-only'
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-node@v4
        with:
          node-version: "18"
          cache: npm
      - run: npm ci
      - run: npm run lint

# ---------------------------------------------------------
# 3. Test
# ---------------------------------------------------------
  test:
    name: "ğŸ§ª Test"
    runs-on: ubuntu-latest
    needs: lint
    if: github.event.inputs.mode != 'docker-only'
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-node@v4
        with:
          node-version: "18"
          cache: npm
      - run: npm ci
      - run: npm run test:ci

# ---------------------------------------------------------
# 4. Security Scan
# ---------------------------------------------------------
  security-scan:
    name: "ğŸ›¡ï¸ Security Scan"
    runs-on: ubuntu-latest
    needs: lint

    steps:
      - name: "ğŸ” Checkout"
        uses: actions/checkout@v4

      - name: "ğŸ” Validate SNYK_TOKEN"
        run: |
          if [ -z "$SNYK_TOKEN" ]; then
            echo "âŒ SNYK_TOKEN secret is missing"
            exit 1
          fi
        env:
          SNYK_TOKEN: ${{ secrets.SNYK_TOKEN }}

      - name: "ğŸ” Snyk Test (Fail on vulnerabilities)"
        uses: snyk/actions/node@v1
        env:
          SNYK_TOKEN: ${{ secrets.SNYK_TOKEN }}
        with:
          command: test

      - name: "ğŸ“Š Snyk Monitor (Send report to dashboard)"
        if: always()
        uses: snyk/actions/node@v1
        env:
          SNYK_TOKEN: ${{ secrets.SNYK_TOKEN }}
        with:
          command: monitor

# ---------------------------------------------------------
# 5. Build
# ---------------------------------------------------------
  build:
    name: "ğŸ—ï¸ Build"
    runs-on: ubuntu-latest
    needs: [test, security-scan]
    if: github.event.inputs.mode == 'full-pipeline'
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-node@v4
        with:
          node-version: "18"
          cache: npm
      - run: npm ci
      - run: npm run build

# ---------------------------------------------------------
# 6. Build & Push to ECR (Frontend & Backend)
# ---------------------------------------------------------
  docker:
    name: "ğŸ³ Build & Push to ECR"
    runs-on: ubuntu-latest
    needs: build
    if: always() && (needs.build.result == 'success' || github.event.inputs.mode == 'docker-only')
    outputs:
      frontend-image-uri: ${{ steps.build-frontend.outputs.image }}
      backend-image-uri: ${{ steps.build-backend.outputs.image }}
      branch-datetime-tag: ${{ steps.build-frontend.outputs.branch-datetime-tag }}
    steps:
      - name: "ğŸ” Checkout"
        uses: actions/checkout@v4

      - name: "ğŸ”‘ Configure AWS Credentials"
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}

      - name: "ğŸ“¦ Create ECR Repositories (if not exists)"
        run: |
          echo "ğŸ” Verifying ECR repositories (managed by Terraform)..."
          
          # Verify frontend repository exists
          echo "Frontend repository: $ECR_REPOSITORY_FRONTEND"
          if aws ecr describe-repositories --repository-names $ECR_REPOSITORY_FRONTEND --region $AWS_REGION 2>/dev/null; then
            echo "âœ… Frontend ECR repository exists: $ECR_REPOSITORY_FRONTEND"
          else
            echo "âŒ Frontend ECR repository not found: $ECR_REPOSITORY_FRONTEND"
            echo "ğŸ’¡ Please run 'terraform apply' first to create ECR repositories"
            exit 1
          fi
          
          # Verify backend repository exists
          echo "Backend repository: $ECR_REPOSITORY_BACKEND"
          if aws ecr describe-repositories --repository-names $ECR_REPOSITORY_BACKEND --region $AWS_REGION 2>/dev/null; then
            echo "âœ… Backend ECR repository exists: $ECR_REPOSITORY_BACKEND"
          else
            echo "âŒ Backend ECR repository not found: $ECR_REPOSITORY_BACKEND"
            echo "ğŸ’¡ Please run 'terraform apply' first to create ECR repositories"
            exit 1
          fi

      - name: "ğŸ—ï¸ Login to Amazon ECR"
        id: login-ecr
        uses: aws-actions/amazon-ecr-login@v2

      - name: "ğŸ³ Build, tag, and push Frontend image to Amazon ECR"
        id: build-frontend
        env:
          ECR_REGISTRY: ${{ steps.login-ecr.outputs.registry }}
        run: |
          # Generate datetime tag
          DATETIME_TAG=$(date +'%Y%m%d-%H%M%S')
          BRANCH_CLEAN=$(echo "${{ github.ref_name }}" | sed 's/[^a-zA-Z0-9._-]/-/g')
          
          # Build and tag with multiple tags
          docker build -t $ECR_REGISTRY/$ECR_REPOSITORY_FRONTEND:$IMAGE_TAG .
          docker build -t $ECR_REGISTRY/$ECR_REPOSITORY_FRONTEND:latest .
          docker build -t $ECR_REGISTRY/$ECR_REPOSITORY_FRONTEND:${BRANCH_CLEAN}-${DATETIME_TAG} .
          docker build -t $ECR_REGISTRY/$ECR_REPOSITORY_FRONTEND:${BRANCH_CLEAN}-latest .
          
          # Push all tags
          docker push $ECR_REGISTRY/$ECR_REPOSITORY_FRONTEND:$IMAGE_TAG
          docker push $ECR_REGISTRY/$ECR_REPOSITORY_FRONTEND:latest
          docker push $ECR_REGISTRY/$ECR_REPOSITORY_FRONTEND:${BRANCH_CLEAN}-${DATETIME_TAG}
          docker push $ECR_REGISTRY/$ECR_REPOSITORY_FRONTEND:${BRANCH_CLEAN}-latest
          
          # Output the main image reference
          echo "image=$ECR_REGISTRY/$ECR_REPOSITORY_FRONTEND:$IMAGE_TAG" >> $GITHUB_OUTPUT
          echo "branch-datetime-tag=${BRANCH_CLEAN}-${DATETIME_TAG}" >> $GITHUB_OUTPUT

      - name: "ğŸ³ Build, tag, and push Backend image to Amazon ECR"
        id: build-backend
        env:
          ECR_REGISTRY: ${{ steps.login-ecr.outputs.registry }}
        run: |
          # Generate datetime tag
          DATETIME_TAG=$(date +'%Y%m%d-%H%M%S')
          BRANCH_CLEAN=$(echo "${{ github.ref_name }}" | sed 's/[^a-zA-Z0-9._-]/-/g')
          
          # Build and tag with multiple tags using backend Dockerfile
          docker build -f Dockerfile.backend -t $ECR_REGISTRY/$ECR_REPOSITORY_BACKEND:$IMAGE_TAG .
          docker build -f Dockerfile.backend -t $ECR_REGISTRY/$ECR_REPOSITORY_BACKEND:latest .
          docker build -f Dockerfile.backend -t $ECR_REGISTRY/$ECR_REPOSITORY_BACKEND:${BRANCH_CLEAN}-${DATETIME_TAG} .
          docker build -f Dockerfile.backend -t $ECR_REGISTRY/$ECR_REPOSITORY_BACKEND:${BRANCH_CLEAN}-latest .
          
          # Push all tags
          docker push $ECR_REGISTRY/$ECR_REPOSITORY_BACKEND:$IMAGE_TAG
          docker push $ECR_REGISTRY/$ECR_REPOSITORY_BACKEND:latest
          docker push $ECR_REGISTRY/$ECR_REPOSITORY_BACKEND:${BRANCH_CLEAN}-${DATETIME_TAG}
          docker push $ECR_REGISTRY/$ECR_REPOSITORY_BACKEND:${BRANCH_CLEAN}-latest
          
          # Output the main image reference
          echo "image=$ECR_REGISTRY/$ECR_REPOSITORY_BACKEND:$IMAGE_TAG" >> $GITHUB_OUTPUT
          
          # Display pushed tags
          echo "ğŸ“¦ Pushed Docker images with tags:"
          echo "Frontend:"
          echo "  â€¢ $IMAGE_TAG (commit SHA)"
          echo "  â€¢ latest (always latest)"
          echo "  â€¢ ${BRANCH_CLEAN}-${DATETIME_TAG} (branch + datetime)"
          echo "  â€¢ ${BRANCH_CLEAN}-latest (branch latest)"
          echo "Backend:"
          echo "  â€¢ $IMAGE_TAG (commit SHA)"
          echo "  â€¢ latest (always latest)"
          echo "  â€¢ ${BRANCH_CLEAN}-${DATETIME_TAG} (branch + datetime)"
          echo "  â€¢ ${BRANCH_CLEAN}-latest (branch latest)"

      - name: "ğŸ” Scan Frontend image for vulnerabilities"
        uses: aquasecurity/trivy-action@master
        with:
          image-ref: ${{ steps.build-frontend.outputs.image }}
          format: 'sarif'
          output: 'trivy-frontend-results.sarif'
        continue-on-error: true

      - name: "ğŸ” Scan Backend image for vulnerabilities"
        uses: aquasecurity/trivy-action@master
        with:
          image-ref: ${{ steps.build-backend.outputs.image }}
          format: 'sarif'
          output: 'trivy-backend-results.sarif'
        continue-on-error: true

      - name: "ğŸ“‹ Check Trivy results"
        run: |
          for file in trivy-frontend-results.sarif trivy-backend-results.sarif; do
            if [ -f "$file" ]; then
              echo "âœ… $file scan completed successfully"
              echo "ğŸ“Š SARIF file size: $(wc -c < $file) bytes"
            else
              echo "âš ï¸  $file not found, creating empty SARIF"
              echo '{"version":"2.1.0","runs":[]}' > $file
            fi
          done

      - name: "ğŸ“Š Upload Frontend Trivy scan results"
        uses: github/codeql-action/upload-sarif@v4
        if: always() && hashFiles('trivy-frontend-results.sarif') != ''
        with:
          sarif_file: 'trivy-frontend-results.sarif'
          category: 'frontend'

      - name: "ğŸ“Š Upload Backend Trivy scan results"  
        uses: github/codeql-action/upload-sarif@v4
        if: always() && hashFiles('trivy-backend-results.sarif') != ''
        with:
          sarif_file: 'trivy-backend-results.sarif'
          category: 'backend'

# ---------------------------------------------------------
# 7. Deploy to AWS EKS
# ---------------------------------------------------------
  deploy-eks:
    name: "â˜¸ï¸ Deploy to AWS EKS"
    runs-on: ubuntu-latest
    needs: docker
    if: github.event.inputs.mode != 'build-only'
    environment: ${{ github.event.inputs.environment || 'dev' }}
    
    steps:
      - name: "ğŸ” Checkout"
        uses: actions/checkout@v4

      - name: "ğŸ”‘ Configure AWS Credentials"
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}

      - name: "âš™ï¸ Setup kubectl"
        uses: azure/setup-kubectl@v4
        with:
          version: v1.29.0

      - name: "ğŸ”— Update kubeconfig for EKS"
        run: |
          echo "ğŸ” Environment: ${{ github.event.inputs.environment || 'dev' }}"
          echo "ğŸ¯ Looking for EKS cluster: $EKS_CLUSTER_NAME"
          echo "ğŸŒ In region: $AWS_REGION"
          
          # Test AWS CLI authentication
          echo "ğŸ” Testing AWS CLI authentication..."
          aws sts get-caller-identity
          
          # Check if cluster exists
          echo "ğŸ” Checking if EKS cluster exists..."
          if aws eks describe-cluster --name $EKS_CLUSTER_NAME --region $AWS_REGION; then
            echo "âœ… EKS cluster found"
          else
            echo "âŒ EKS cluster not found or not accessible"
            echo "Available clusters:"
            aws eks list-clusters --region $AWS_REGION || echo "Failed to list clusters"
            exit 1
          fi
          
          # Update kubeconfig
          echo "ğŸ”„ Updating kubeconfig..."
          aws eks update-kubeconfig --region $AWS_REGION --name $EKS_CLUSTER_NAME
          
          # Test cluster connectivity
          echo "ğŸ”— Testing cluster connectivity..."
          if kubectl cluster-info; then
            echo "âœ… Successfully connected to cluster"
          else
            echo "âŒ Failed to connect to cluster"
            exit 1
          fi
          
          # Show current context
          echo "ğŸ“‹ Current kubectl context:"
          kubectl config current-context

      - name: "âœ… Verify Cluster Access"
        run: |
          echo "ğŸ” Verifying cluster access and permissions..."
          
          # Check nodes
          echo "ğŸ–¥ï¸ Cluster nodes:"
          kubectl get nodes -o wide
          
          # Check current namespace and permissions
          echo "ğŸ“ Current namespace:"
          kubectl config view --minify --output 'jsonpath={..namespace}' || echo 'default'
          
          # Test basic permissions
          echo "ğŸ” Testing basic permissions:"
          kubectl auth can-i get pods
          kubectl auth can-i create deployments
          kubectl auth can-i patch deployments
          
          # Show existing resources
          echo "ğŸ“¦ Existing Kudos app resources:"
          kubectl get all -l "app in (kudos-frontend,kudos-backend)" || echo "No existing resources found"

      - name: "ğŸ§¹ Cleanup stuck resources"
        run: |
          echo "ğŸ§¹ Checking for stuck resources..."
          
          # Test kubectl connectivity first
          echo "ğŸ” Testing kubectl connectivity..."
          if ! kubectl get nodes; then
            echo "âŒ Cannot connect to cluster"
            exit 1
          fi
          
          # Check current namespace
          echo "ğŸ“ Current namespace: $(kubectl config view --minify --output 'jsonpath={..namespace}' || echo 'default')"
          
          # Check for stuck pods and remove them
          echo "ğŸ” Looking for stuck frontend pods..."
          STUCK_FRONTEND=$(kubectl get pods -l app=kudos-frontend --field-selector=status.phase=Failed -o name 2>/dev/null || echo "")
          echo "ğŸ” Looking for stuck backend pods..."
          STUCK_BACKEND=$(kubectl get pods -l app=kudos-backend --field-selector=status.phase=Failed -o name 2>/dev/null || echo "")
          
          if [ ! -z "$STUCK_FRONTEND" ]; then
            echo "ğŸ—‘ï¸ Removing stuck frontend pods: $STUCK_FRONTEND"
            kubectl delete $STUCK_FRONTEND || echo "Failed to delete some frontend pods"
          else
            echo "âœ… No stuck frontend pods found"
          fi
          
          if [ ! -z "$STUCK_BACKEND" ]; then
            echo "ğŸ—‘ï¸ Removing stuck backend pods: $STUCK_BACKEND"
            kubectl delete $STUCK_BACKEND || echo "Failed to delete some backend pods"
          else
            echo "âœ… No stuck backend pods found"
          fi
          
          # Show current pod status
          echo "ğŸ“Š Current pod status:"
          kubectl get pods -l "app in (kudos-frontend,kudos-backend)" --show-labels || echo "No pods found"

      - name: "ğŸ—ï¸ Prepare for Deployment"
        run: |
          # Get ECR registry dynamically
          ECR_REGISTRY=$(aws sts get-caller-identity --query Account --output text).dkr.ecr.$AWS_REGION.amazonaws.com
          FRONTEND_IMAGE_NAME=$ECR_REGISTRY/$ECR_REPOSITORY_FRONTEND:latest
          BACKEND_IMAGE_NAME=$ECR_REGISTRY/$ECR_REPOSITORY_BACKEND:latest
          
          echo "ğŸ” Will use images:"
          echo "Frontend: $FRONTEND_IMAGE_NAME"
          echo "Backend: $BACKEND_IMAGE_NAME"
          
          # Verify images exist in ECR
          echo "ğŸ” Verifying images exist in ECR..."
          if aws ecr describe-images --repository-name $ECR_REPOSITORY_FRONTEND --region $AWS_REGION --image-ids imageTag=latest >/dev/null 2>&1; then
            echo "âœ… Frontend image exists"
          else
            echo "âŒ Frontend image not found"
            exit 1
          fi
          
          if aws ecr describe-images --repository-name $ECR_REPOSITORY_BACKEND --region $AWS_REGION --image-ids imageTag=latest >/dev/null 2>&1; then
            echo "âœ… Backend image exists"
          else
            echo "âŒ Backend image not found"
            exit 1
          fi

      - name: "ğŸš€ Deploy to EKS"
        run: |
          echo "ğŸš€ Deploying to EKS cluster: $EKS_CLUSTER_NAME"
          
          # Apply all manifests at once using kustomize
          echo "ğŸ“¦ Applying all Kubernetes manifests..."
          if kubectl apply -k k8s/; then
            echo "âœ… All manifests applied successfully"
          else
            echo "âŒ Failed to apply manifests"
            echo "ğŸ” Recent cluster events:"
            kubectl get events --sort-by='.lastTimestamp' | tail -10
            exit 1
          fi
          
          # Show deployment status immediately after apply
          echo "ğŸ“Š Deployment status after apply:"
          kubectl get deployments
          kubectl get pods -l "app in (kudos-frontend,kudos-backend)"
          kubectl get services
          
          # Add labels for tracking (only if deployments were created)
          echo "ğŸ·ï¸ Adding tracking labels..."
          kubectl label deployment/kudos-frontend version=$IMAGE_TAG --overwrite || echo "âš ï¸ Failed to label frontend deployment"
          kubectl label deployment/kudos-frontend environment=${{ github.event.inputs.environment || 'dev' }} --overwrite || echo "âš ï¸ Failed to label frontend deployment"
          kubectl label deployment/kudos-backend version=$IMAGE_TAG --overwrite || echo "âš ï¸ Failed to label backend deployment"
          kubectl label deployment/kudos-backend environment=${{ github.event.inputs.environment || 'dev' }} --overwrite || echo "âš ï¸ Failed to label backend deployment"

      - name: "â³ Wait for Deployment Rollout"
        run: |
          echo "â³ Waiting for deployments to complete..."
          
          # Check initial deployment status
          echo "ğŸ“Š Initial deployment status:"
          kubectl get deployments
          kubectl describe deployment kudos-frontend
          kubectl describe deployment kudos-backend
          
          # Wait for frontend rollout with diagnostics
          echo "ğŸ”„ Rolling out frontend deployment..."
          if kubectl rollout status deployment/kudos-frontend --timeout=600s; then
            echo "âœ… Frontend rollout completed successfully"
          else
            echo "âŒ Frontend rollout failed or timed out"
            echo "ğŸ” Frontend deployment events:"
            kubectl get events --field-selector involvedObject.name=kudos-frontend --sort-by='.lastTimestamp'
            echo "ğŸ” Frontend pod status:"
            kubectl get pods -l app=kudos-frontend -o wide
            kubectl describe pods -l app=kudos-frontend | tail -20
            exit 1
          fi
          
          # Wait for backend rollout with diagnostics
          echo "ğŸ”„ Rolling out backend deployment..."
          if kubectl rollout status deployment/kudos-backend --timeout=600s; then
            echo "âœ… Backend rollout completed successfully"
          else
            echo "âŒ Backend rollout failed or timed out"
            echo "ğŸ” Backend deployment events:"
            kubectl get events --field-selector involvedObject.name=kudos-backend --sort-by='.lastTimestamp'
            echo "ğŸ” Backend pod status:"
            kubectl get pods -l app=kudos-backend -o wide
            kubectl describe pods -l app=kudos-backend | tail -20
            exit 1
          fi
          
          echo "âœ… All deployments completed successfully!"

      - name: "ğŸ” Verify Deployment"
        run: |
          echo "ğŸ” Checking deployment status..."
          kubectl get deployments
          kubectl get pods -l app=kudos-frontend
          kubectl get pods -l app=kudos-backend
          kubectl get services

      # ---- HEALTH CHECK VALIDATION ----
      - name: "ğŸ¥ Application Health Check"
        run: |
          echo "ğŸ¥ Running application health checks..."
          
          # Wait a moment for pods to stabilize
          echo "â³ Waiting for pods to stabilize..."
          sleep 30
          
          # Check pod status
          echo "ğŸ“Š Pod Status:"
          kubectl get pods -l "app in (kudos-frontend,kudos-backend)" -o wide
          
          # Simple backend health check
          echo "ğŸ” Testing Backend Health..."
          BACKEND_POD=$(kubectl get pods -l app=kudos-backend -o jsonpath='{.items[0].metadata.name}')
          
          if [ ! -z "$BACKEND_POD" ]; then
            echo "Backend pod: $BACKEND_POD"
            
            # Check backend logs
            echo "ğŸ“‹ Backend logs:"
            kubectl logs $BACKEND_POD --tail=10
            
            # Test backend health endpoint via port-forward
            kubectl port-forward $BACKEND_POD 3001:3001 &
            PF_PID=$!
            sleep 10
            
            HEALTH_STATUS=$(curl -s -o /dev/null -w "%{http_code}" http://localhost:3001/health || echo "000")
            kill $PF_PID 2>/dev/null || true
            
            if [ "$HEALTH_STATUS" = "200" ]; then
              echo "âœ… Backend health check passed"
            else
              echo "âš ï¸ Backend health check returned HTTP $HEALTH_STATUS"
            fi
          else
            echo "âŒ No backend pod found"
          fi
          
          # Simple frontend health check
          echo "ğŸ” Testing Frontend Health..."
          FRONTEND_POD=$(kubectl get pods -l app=kudos-frontend -o jsonpath='{.items[0].metadata.name}')
          
          if [ ! -z "$FRONTEND_POD" ]; then
            echo "Frontend pod: $FRONTEND_POD"
            
            # Check frontend logs
            echo "ğŸ“‹ Frontend logs:"
            kubectl logs $FRONTEND_POD --tail=5 || echo "âš ï¸ Could not fetch frontend logs"
            
            echo "âœ… Frontend pod is running"
          else
            echo "âŒ No frontend pod found"
          fi
          
          echo "âœ… Health checks completed"

      - name: "ğŸ“Š Deployment Summary"
        if: always()
        run: |
          echo "ğŸ“Š === DEPLOYMENT SUMMARY ==="
          echo "ğŸ”– Environment: ${{ github.event.inputs.environment || 'dev' }}"
          echo "ï¿½ Branch: ${{ github.ref_name }}"
          echo "ğŸ·ï¸  Image Tag: $IMAGE_TAG"

          echo "ğŸ¯ EKS Cluster: $EKS_CLUSTER_NAME"
          echo "ğŸŒ AWS Region: $AWS_REGION"
          echo ""
          echo "ğŸ“‹ Final Status:"
          kubectl get deployment/kudos-frontend -o wide
          echo ""
          echo "ğŸ”— Service Details:"
          kubectl get service/kudos-frontend -o wide
          kubectl get service/kudos-backend -o wide

# ---------------------------------------------------------
# 8. Post-Deployment Validation & Notifications
# ---------------------------------------------------------
  post-deployment:
    name: "ğŸ“‹ Post-Deployment Validation"
    runs-on: ubuntu-latest
    needs: deploy-eks
    if: always()

    steps:
      - name: "ğŸ”‘ Configure AWS Credentials"
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}

      - name: "âš™ï¸ Setup kubectl"
        uses: azure/setup-kubectl@v4
        with:
          version: v1.29.0

      - name: "ğŸ”— Update kubeconfig for EKS"
        run: |
          echo "ğŸ” Environment: ${{ github.event.inputs.environment || 'dev' }}"
          echo "ğŸ¯ Looking for EKS cluster: $EKS_CLUSTER_NAME" 
          echo "ğŸŒ In region: $AWS_REGION"
          aws eks update-kubeconfig --region $AWS_REGION --name $EKS_CLUSTER_NAME

      - name: "ğŸ“Š Generate Deployment Report"
        run: |
          echo "# ğŸ“Š Deployment Report" > deployment-report.md
          echo "" >> deployment-report.md
          echo "**Environment:** ${{ github.event.inputs.environment || 'dev' }}" >> deployment-report.md
          echo "**Branch:** ${{ github.ref_name }}" >> deployment-report.md
          echo "**Image Tag:** $IMAGE_TAG" >> deployment-report.md
          echo "**Deployment Time:** $(date -u)" >> deployment-report.md
          echo "**Commit SHA:** ${{ github.sha }}" >> deployment-report.md
          echo "" >> deployment-report.md
          echo "## Application Status" >> deployment-report.md
          echo '```' >> deployment-report.md
          kubectl get deployment/kudos-frontend -o wide >> deployment-report.md
          kubectl get deployment/kudos-backend -o wide >> deployment-report.md
          echo '```' >> deployment-report.md
          echo "" >> deployment-report.md
          echo "## Pods Status" >> deployment-report.md
          echo '```' >> deployment-report.md
          kubectl get pods -l app=kudos-frontend >> deployment-report.md
          kubectl get pods -l app=kudos-backend >> deployment-report.md
          echo '```' >> deployment-report.md

      - name: "ğŸ“§ Deployment Success Notification"
        if: needs.deploy-eks.result == 'success'
        run: |
          echo "âœ… Deployment completed successfully!"
          echo "ğŸ¯ Environment: ${{ github.event.inputs.environment || 'dev' }}"
          echo "ğŸ·ï¸  Image: $IMAGE_TAG"

      - name: "ğŸš¨ Deployment Failure Notification"
        if: needs.deploy-eks.result == 'failure'
        run: |
          echo "âŒ Deployment failed!"
          echo "ğŸ” Check the logs above for details"
          kubectl get events --sort-by='.lastTimestamp' || true
